{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Mean: 100%|██████████| 2/2 [00:15<00:00,  7.55s/it]\n",
      "Calculating Std: 100%|██████████| 2/2 [00:14<00:00,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics saved to statistics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "def calculate_statistics(folder_path, sample_size=40):\n",
    "    # Initialize variables to store sum and count for each channel\n",
    "    nersc_sar_primary_sum = 0\n",
    "    nersc_sar_primary_count = 0\n",
    "    nersc_sar_secondary_sum = 0\n",
    "    nersc_sar_secondary_count = 0\n",
    "    sar_incidenceangle_sum = 0\n",
    "    sar_incidenceangle_count = 0\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".nc\")]\n",
    "     # Randomly select 'sample_size' files from the list\n",
    "    selected_files = random.sample(files, min(len(files), sample_size))\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in tqdm(selected_files, desc='Calculating Mean'):\n",
    "            with xr.open_dataset(os.path.join(folder_path,filename), engine='h5netcdf') as nc_file:\n",
    "                # Extract data for each channel\n",
    "                nersc_sar_primary_data = nc_file.variables['nersc_sar_primary'].values\n",
    "                nersc_sar_primary_data = nersc_sar_primary_data.flatten()[~np.isnan(nersc_sar_primary_data.flatten())]\n",
    "                nersc_sar_secondary_data = nc_file.variables['nersc_sar_secondary'].values\n",
    "                nersc_sar_secondary_data = nersc_sar_secondary_data.flatten()[~np.isnan(nersc_sar_secondary_data.flatten())]\n",
    "                sar_incidenceangle_data = nc_file.variables['sar_grid_incidenceangle'].values\n",
    "                sar_incidenceangle_data = sar_incidenceangle_data.flatten()[~np.isnan(sar_incidenceangle_data.flatten())]\n",
    "\n",
    "                \n",
    "                # Update sum and count for each channel\n",
    "                nersc_sar_primary_sum += np.sum(nersc_sar_primary_data)\n",
    "                nersc_sar_primary_count += nersc_sar_primary_data.size\n",
    "                nersc_sar_secondary_sum += np.sum(nersc_sar_secondary_data)\n",
    "                nersc_sar_secondary_count += nersc_sar_secondary_data.size\n",
    "                sar_incidenceangle_sum += np.sum(sar_incidenceangle_data)\n",
    "                sar_incidenceangle_count += sar_incidenceangle_data.size\n",
    "\n",
    "    # Calculate mean for each channel\n",
    "    nersc_sar_primary_mean = nersc_sar_primary_sum / nersc_sar_primary_count\n",
    "    nersc_sar_secondary_mean = nersc_sar_secondary_sum / nersc_sar_secondary_count\n",
    "    sar_incidenceangle_mean = sar_incidenceangle_sum / sar_incidenceangle_count\n",
    "\n",
    "    # Re-iterate to calculate standard deviation for each channel\n",
    "    nersc_sar_primary_sum_of_squares = 0\n",
    "    nersc_sar_secondary_sum_of_squares = 0\n",
    "    sar_incidenceangle_sum_of_squares = 0\n",
    "    for filename in tqdm(selected_files, desc='Calculating Std'):\n",
    "            with xr.open_dataset(os.path.join(folder_path,filename), engine='h5netcdf') as nc_file:\n",
    "                nersc_sar_primary_data = nc_file.variables['nersc_sar_primary'].values\n",
    "                nersc_sar_primary_data = nersc_sar_primary_data.flatten()[~np.isnan(nersc_sar_primary_data.flatten())]\n",
    "                nersc_sar_secondary_data = nc_file.variables['nersc_sar_secondary'].values\n",
    "                nersc_sar_secondary_data = nersc_sar_secondary_data.flatten()[~np.isnan(nersc_sar_secondary_data.flatten())]\n",
    "                sar_incidenceangle_data = nc_file.variables['sar_grid_incidenceangle'].values\n",
    "                sar_incidenceangle_data = sar_incidenceangle_data.flatten()[~np.isnan(sar_incidenceangle_data.flatten())]\n",
    "\n",
    "                nersc_sar_primary_sum_of_squares += np.sum((nersc_sar_primary_data - nersc_sar_primary_mean) ** 2)\n",
    "                nersc_sar_secondary_sum_of_squares += np.sum((nersc_sar_secondary_data - nersc_sar_secondary_mean) ** 2)\n",
    "                sar_incidenceangle_sum_of_squares += np.sum((sar_incidenceangle_data - sar_incidenceangle_mean) ** 2) \n",
    "\n",
    "    # Calculate standard deviation for each channel\n",
    "    nersc_sar_primary_std = np.sqrt(nersc_sar_primary_sum_of_squares / nersc_sar_primary_count)\n",
    "    nersc_sar_secondary_std = np.sqrt(nersc_sar_secondary_sum_of_squares / nersc_sar_secondary_count)\n",
    "    sar_incidenceangle_std = np.sqrt(sar_incidenceangle_sum_of_squares / sar_incidenceangle_count)\n",
    "\n",
    "    return (nersc_sar_primary_mean, nersc_sar_primary_std), (nersc_sar_secondary_mean, nersc_sar_secondary_std), \\\n",
    "           (sar_incidenceangle_mean, sar_incidenceangle_std)\n",
    "\n",
    "def save_to_txt(means_primary, stds_primary, means_secondary, stds_secondary, means_incidenceangle, stds_incidenceangle ,output_file):\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(\"Channel\\tMean\\tStandard Deviation\\n\")\n",
    "        file.write(\"nersc_sar_primary\\t{}\\t{}\\n\".format(means_primary, stds_primary))\n",
    "        file.write(\"nersc_sar_secondary\\t{}\\t{}\\n\".format(means_secondary, stds_secondary))\n",
    "        file.write(\"sar_incidenceangle\\t{}\\t{}\\n\".format(means_incidenceangle, stds_incidenceangle))\n",
    "\n",
    "# Example usage\n",
    "folder_path = '/home/m32patel/projects/def-dclausi/AI4arctic/dataset/ai4arctic_raw_train_v3'\n",
    "output_file = 'statistics.txt'\n",
    "\n",
    "statistics = calculate_statistics(folder_path, sample_size=533)\n",
    "\n",
    "# Unpack the results\n",
    "means_primary, stds_primary = statistics[0]\n",
    "means_secondary, stds_secondary = statistics[1]\n",
    "means_incidenceangle, stds_incidenceangle = statistics[2]\n",
    "\n",
    "save_to_txt(means_primary, stds_primary, means_secondary, stds_secondary, means_incidenceangle, stds_incidenceangle ,output_file)\n",
    "print(\"Statistics saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " scene = xr.open_dataset('/home/m32patel/projects/def-dclausi/AI4arctic/dataset/ai4arctic_raw_train_v3/S1B_EW_GRDM_1SDH_20211222T105953_20211222T110047_030137_039940_D955_icechart_cis_SGRDIFOXE_20211222T1059Z_pl_a.nc', engine='h5netcdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = scene.variables['nersc_sar_primary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(scene.variables['nersc_sar_primary'].values, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_mmselfsup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
